{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "# print(os.path.realpath(__file__))\n",
    "sys.path.append(str(Path(sys.argv[0]).absolute().parent.parent.parent.parent))\n",
    "base_repo = os.path.realpath(os.path.join(os.getcwd(), \"../../\"))\n",
    "print(base_repo)\n",
    "sys.path.append(base_repo)\n",
    "# add the entire folder to path\n",
    "print(sys.path)\n",
    "print(os.getcwd())\n",
    "from src.utils import utils\n",
    "from src.discovery import data\n",
    "from src.discovery import classifier\n",
    "\n",
    "import collections\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "import graphviz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = os.path.realpath('./output/')\n",
    "PATH_TO_CSV = os.path.realpath('../data/raw/2022-10-26_hiscore_data.csv')\n",
    "if PATH_TO_CSV is None or not os.path.exists(PATH_TO_CSV):\n",
    "    print('set PATH_TO_CSV=/path/to/2022-10-26_hiscore_data.csv and run all')\n",
    "    raise ValueError\n",
    "\n",
    "df = pd.read_csv(PATH_TO_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.chdir(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This logic is roughly equivalent to app.py's train function\n",
    "hiscoredata = data.hiscoreData(df, False)\n",
    "features = hiscoredata.features()\n",
    "# no playerData()-related data, its already in features\n",
    "features_labeled = features\n",
    "binary_classifier = classifier.classifier(\"binaryClassifier\")\n",
    "dt_binary_classifier = classifier.DTclassifier(\"DTbinaryClassifier\")\n",
    "# Logic should be the same as app.py line 179: train the model \n",
    "x = features_labeled.copy()\n",
    "y = x['label'].apply(lambda x: 0 if x == 'Real_Player' else 1)\n",
    "x.drop(columns=['label', 'label_id', 'name', 'created_at', 'updated_at', 'account_status', 'possible_ban', 'confirmed_ban'], inplace=True)\n",
    "print('x columns:\\n', x.columns)\n",
    "print('x head:\\n', x.head())\n",
    "print('y head:\\n', y.head())\n",
    "x.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_score(classifier, x, y, class_names=None, rpt=True):\n",
    "    # This logic is roughly equivalent to app.py's train function\n",
    "    train_x, test_x, train_y, test_y = train_test_split(\n",
    "        x, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    classifier.fit(train_x, train_y)\n",
    "\n",
    "    accuracy, roc_auc = classifier.score(test_y, test_x, class_names)\n",
    "    if rpt:\n",
    "        print(f'accuracy: {accuracy}, roc_auc: {roc_auc}')\n",
    "    # OUTPUT: (0.9992126580557206, 0.9992126580557205)\n",
    "    \n",
    "    if rpt:\n",
    "        print(\n",
    "            classification_report(\n",
    "                y_true=test_y, \n",
    "                y_pred=classifier.predict(test_x)\n",
    "            )\n",
    "        )\n",
    "    return accuracy\n",
    "\n",
    "# To inspect binary classifier random forest and decision tree performance:\n",
    "# fit_score(binary_classifier, x, y)\n",
    "# fit_score(dt_binary_classifier, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of block is x_multi, y_multi. Fiddle around with data here.\n",
    "multi_classifier = classifier.classifier(\"multiClassifier\")\n",
    "dt_multi_classifier = classifier.DTclassifier(\"DTmultiClassifier\")\n",
    "y_labels = features_labeled['label'].value_counts()\n",
    "y_labels = [label for label, value in y_labels.items() if value > 500]\n",
    "# To inspect just bots:\n",
    "# y_labels.remove('Real_Player')\n",
    "x_multi = features_labeled.copy()\n",
    "x_multi = x_multi[x_multi['label'].isin(y_labels)]\n",
    "label_to_id = dict((label, label_id) for label_id, label in enumerate(x_multi['label'].unique()))\n",
    "y_multi = x_multi['label'] #.apply(lambda x: label_to_id[x])\n",
    "x_multi.drop(columns=['label', 'label_id', 'name', 'created_at', 'updated_at', 'account_status', 'possible_ban', 'confirmed_ban'], inplace=True)\n",
    "\n",
    "enum_label = list(enumerate(y_multi.unique()))\n",
    "class_names = [t[1] for t in enum_label]\n",
    "label_to_enum = dict([(k, v) for v, k in enum_label])\n",
    "\n",
    "x_multi = x_multi[x_multi.columns.drop(list(x_multi.filter(regex='/total')))]\n",
    "\n",
    "print('x_multi columns:\\n', x_multi.columns)\n",
    "print('x_multi head:\\n', x_multi.head())\n",
    "print('y_multi head:\\n', y_multi.head())\n",
    "# To inspect multiclassifier random forest and decision tree performance:\n",
    "#fit_score(multi_classifier, x_multi, y_multi)\n",
    "#fit_score(dt_multi_classifier, x_multi, y_multi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a decision tree and output info about the set of samples that end up in each leaf node.\n",
    "# Loosely based on: https://stackoverflow.com/a/66299085/5024503\n",
    "def retrieve_branches(number_nodes, children_left_list, children_right_list):\n",
    "    \"\"\"Retrieve decision tree branches\"\"\"\n",
    "    \n",
    "    # Calculate if a node is a leaf\n",
    "    is_leaves_list = [(False if cl != cr else True) for cl, cr in zip(children_left_list, children_right_list)]\n",
    "    \n",
    "    # Store the branches paths\n",
    "    paths = []\n",
    "    \n",
    "    for i in range(number_nodes):\n",
    "        if is_leaves_list[i]:\n",
    "            # Search leaf node in previous paths\n",
    "            end_node = [path[-1] for path in paths]\n",
    "\n",
    "            # If it is a leave node yield the path\n",
    "            if i in end_node:\n",
    "                output = paths.pop(np.argwhere(i == np.array(end_node))[0][0])\n",
    "                yield output\n",
    "\n",
    "        else:\n",
    "            \n",
    "            # Origin and end nodes\n",
    "            origin, end_l, end_r = i, children_left_list[i], children_right_list[i]\n",
    "\n",
    "            # Iterate over previous paths to add nodes\n",
    "            for index, path in enumerate(paths):\n",
    "                if origin == path[-1]:\n",
    "                    paths[index] = path + [end_l]\n",
    "                    paths.append(path + [end_r])\n",
    "\n",
    "            # Initialize path in first iteration\n",
    "            if i == 0:\n",
    "                paths.append([i, children_left[i]])\n",
    "                paths.append([i, children_right[i]])\n",
    "\n",
    "def print_node_info(label, node_info, feature, threshold, y_multi, col_names, x_multi, samp_to_leaf, label_i):\n",
    "    labels = sorted(y_multi.unique())\n",
    "    leaf_index, branch_idx, branch, impurity, nsamples, ntotal, value = node_info\n",
    "    indent = '\\t\\t\\t'\n",
    "    pct_samples = 100.0 * float(nsamples)/float(ntotal)\n",
    "    \n",
    "    file_stem = f'{label}-{label_i}'\n",
    "    with open(f'{file_stem}.txt', 'w') as f: \n",
    "        f.write(f\"---------------------------------------------------------------------------------------\\n\")\n",
    "        f.write(f'{indent}Branch: {branch_idx}, Path: {branch}\\n')\n",
    "        f.write(f'{indent}{nsamples} in node ({pct_samples}%)\\n')\n",
    "        f.write(f'{indent}Gin {impurity} at leaf node {branch[-1]}\\n')\n",
    "        label_vals = sorted(zip(labels, value), key=lambda tup: tup[1], reverse=True)\n",
    "        weights_str = ' '.join(f'{l}:{int(v)}' for l, v in label_vals)\n",
    "        f.write(f'{indent}Value: {weights_str}\\n')\n",
    "        l = []\n",
    "        # Use a feature vector that falls in this leaf_index to determine '<=' or '>'\n",
    "        samp_idxs_in_leaf = samp_to_leaf.index[samp_to_leaf == leaf_index]\n",
    "        samp_idx_in_leaf = samp_idxs_in_leaf[0]\n",
    "        samp_in_leaf = x_multi.iloc[samp_idx_in_leaf]\n",
    "        samp_idxs_df = x_multi.iloc[samp_idxs_in_leaf]\n",
    "        out_df = samp_idxs_df.copy()\n",
    "        out_df.to_csv(f'{file_stem}.csv')\n",
    "        for elem in branch:\n",
    "            op = '<=' if samp_in_leaf[feature[elem]] <= threshold[elem] else '>' \n",
    "            lvl = '' if col_names[feature[elem]].lower() not in utils.SKILLS else (f'(lvl {utils.XPTable.exp_to_level(threshold[elem])})')\n",
    "            s = f'{col_names[feature[elem]]} {op} {threshold[elem]} {lvl}'\n",
    "            l.append(s)\n",
    "        f.write(f\"{indent}Decision Rules: \" + ', '.join(l) + '\\n')\n",
    "        if pct_samples > 0.5 and label == 'Unknown_bot':\n",
    "            # Compute some stats for this label's common leaf nodes for convenience.\n",
    "            #   You can do this after the .csv files are output, too.\n",
    "            f.write(f\"{indent}{out_df.describe()}\\n\")\n",
    "        f.write(f\"---------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "# above ~10 is too deep to graph, so print helpful output instead.\n",
    "TREE_DEPTH=19\n",
    "print(f'##############################################################')\n",
    "print(f'### Training decision tree with depth {TREE_DEPTH}.#####################')\n",
    "print(f'### Generating a label-id.csv file for each leaf node, where #')\n",
    "print(f'### label is the tree\\'s classification at that node, and #####')\n",
    "print(f'### id is unique for each label. id 0 is the leaf containing #')\n",
    "print(f'### the most samples, 1 the next most, etc... ################')\n",
    "print(f'### Also generating corresponding label-id.txt files, ########')\n",
    "print(f'### containing descriptive info about the .csv file ##########')\n",
    "print(f'##############################################################')\n",
    "clf = classifier.DTclassifier(f\"DTmultiClassifier{TREE_DEPTH}\", max_depth=TREE_DEPTH)\n",
    "score = fit_score(clf, x_multi, y_multi, rpt=True)\n",
    "col_names = x_multi.columns.tolist()\n",
    "\n",
    "n_nodes = clf.tree_.node_count\n",
    "children_left = clf.tree_.children_left\n",
    "children_right = clf.tree_.children_right\n",
    "feature = clf.tree_.feature\n",
    "threshold = clf.tree_.threshold\n",
    "impurity = clf.tree_.impurity\n",
    "value = clf.tree_.value\n",
    "all_branches = list(retrieve_branches(n_nodes, children_left, children_right))\n",
    "label_to_node_info = collections.defaultdict(list)\n",
    "samp_to_leaf = pd.Series(clf.apply(x_multi))\n",
    "leaf_idxs = pd.Series(samp_to_leaf).value_counts()\n",
    "ntotal = leaf_idxs.sum()\n",
    "for index, branch in enumerate(all_branches):\n",
    "    leaf_index = branch[-1]\n",
    "    nsamples = leaf_idxs[leaf_index]\n",
    "    node_info = (leaf_index, index, branch, impurity[leaf_index], nsamples, ntotal, value[leaf_index][0])\n",
    "    label = clf.classes_[np.argmax(value[leaf_index])]\n",
    "    label_to_node_info[label].append(node_info)\n",
    "labels = list(label_to_node_info.keys())\n",
    "for label, v in label_to_node_info.items():\n",
    "    print('###################################################')\n",
    "    print('### Generating label files for: ', label, '########')\n",
    "    print('###################################################')\n",
    "    for i, node_info in enumerate(sorted(v, key=lambda tup: tup[4], reverse=True)):\n",
    "        print_node_info(label, node_info, feature, threshold, y_multi, col_names, x_multi, samp_to_leaf, i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tree.export_text(clf, feature_names=x_multi.columns.tolist(), max_depth=100, show_weights=True, spacing=1)\n",
    "with open('inspect_dt-tree.txt', 'w') as f:\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph some decision trees with lower depths.\n",
    "PLOT_TREES = False\n",
    "if PLOT_TREES:\n",
    "    print('Generating small decision tree images (large ones dont display well)')\n",
    "    scores = []\n",
    "    i_vals = []\n",
    "    for i in range(2, 10):\n",
    "        dt_multi_classifier = classifier.DTclassifier(f\"DTmultiClassifier{i}\", max_depth=i)\n",
    "        score = fit_score(dt_multi_classifier, x_multi, y_multi)\n",
    "        scores.append(score)\n",
    "        i_vals.append(i_vals)\n",
    "        out_file = f'DTmultiClassifer_{i}'\n",
    "        dot_data = tree.export_graphviz(dt_multi_classifier, rotate=True, impurity=False, precision=1, feature_names=x_multi.columns, class_names=sorted(y_multi.unique()))\n",
    "        graph = graphviz.Source(dot_data) \n",
    "        graph.render(filename=out_file, format='pdf')\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10 ipynb kernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
