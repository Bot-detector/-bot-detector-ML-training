{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path(sys.argv[0]).absolute().parent.parent.parent.parent))\n",
    "base_repo = os.path.realpath(os.path.join(os.getcwd(), \"../../\"))\n",
    "print(f\"{base_repo=}\")\n",
    "\n",
    "sys.path.append(base_repo)\n",
    "\n",
    "# add the entire folder to path\n",
    "print(f\"{sys.path=}\")\n",
    "print(f\"{os.getcwd()=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import utils\n",
    "from src.utils import data\n",
    "from src.utils import classifier\n",
    "\n",
    "import collections\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_FILE = f\"../data/raw/2022-10-26_hiscore_data.parquet.gzip\"\n",
    "\n",
    "df = pd.read_parquet(PATH_TO_FILE)\n",
    "df = df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This logic is roughly equivalent to app.py's train function\n",
    "hiscoredata = data.hiscoreData(df, False)\n",
    "features = hiscoredata.features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_classifier = classifier.classifier(\"binaryClassifier\")\n",
    "dt_binary_classifier = classifier.DTclassifier(\"DTbinaryClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = features.copy()\n",
    "x = x.drop(\n",
    "    columns=[\n",
    "        \"label\",\n",
    "        \"label_id\",\n",
    "        \"name\",\n",
    "        \"created_at\",\n",
    "        \"updated_at\",\n",
    "        \"account_status\",\n",
    "        \"possible_ban\",\n",
    "        \"confirmed_ban\",\n",
    "    ]\n",
    ")\n",
    "print(\"x columns:\\n\", x.columns)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = features[\"label\"].apply(lambda x: 0 if x == \"Real_Player\" else 1)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_score(classifier, x, y, class_names=None, rpt=True):\n",
    "    # This logic is roughly equivalent to app.py's train function\n",
    "    train_x, test_x, train_y, test_y = train_test_split(\n",
    "        x, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    classifier.fit(train_x, train_y)\n",
    "\n",
    "    accuracy, roc_auc = classifier.score(test_y, test_x, class_names)\n",
    "    if rpt:\n",
    "        print(f\"accuracy: {accuracy}, roc_auc: {roc_auc}\")\n",
    "    # OUTPUT: (0.9992126580557206, 0.9992126580557205)\n",
    "\n",
    "    if rpt:\n",
    "        print(classification_report(y_true=test_y, y_pred=classifier.predict(test_x)))\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# To inspect binary classifier random forest and decision tree performance:\n",
    "# fit_score(binary_classifier, x, y)\n",
    "# fit_score(dt_binary_classifier, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of block is x_multi, y_multi. Fiddle around with data here.\n",
    "multi_classifier = classifier.classifier(\"multiClassifier\")\n",
    "dt_multi_classifier = classifier.DTclassifier(\"DTmultiClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = features[\"label\"].value_counts()\n",
    "y_labels = [label for label, value in y_labels.items() if value > 500]\n",
    "y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id = dict(\n",
    "    (label, label_id) for label_id, label in enumerate(x_multi[\"label\"].unique())\n",
    ")\n",
    "label_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_multi = features.copy()\n",
    "x_multi = x_multi[x_multi[\"label\"].isin(y_labels)]\n",
    "x_multi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_multi = x_multi[\"label\"]  # .apply(lambda x: label_to_id[x])\n",
    "y_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum_label = list(enumerate(y_multi.unique()))\n",
    "class_names = [t[1] for t in enum_label]\n",
    "label_to_enum = dict([(k, v) for v, k in enum_label])\n",
    "label_to_enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_multi = x_multi.drop(\n",
    "    columns=[\n",
    "        \"label\",\n",
    "        \"label_id\",\n",
    "        \"name\",\n",
    "        \"created_at\",\n",
    "        \"updated_at\",\n",
    "        \"account_status\",\n",
    "        \"possible_ban\",\n",
    "        \"confirmed_ban\",\n",
    "    ]\n",
    ")\n",
    "x_multi = x_multi[x_multi.columns.drop(list(x_multi.filter(regex=\"/total\")))]\n",
    "x_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_multi columns:\\n\", x_multi.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a decision tree and output info about the set of samples that end up in each leaf node.\n",
    "# Loosely based on: https://stackoverflow.com/a/66299085/5024503\n",
    "def retrieve_branches(number_nodes, children_left_list, children_right_list):\n",
    "    \"\"\"Retrieve decision tree branches\"\"\"\n",
    "\n",
    "    # Calculate if a node is a leaf\n",
    "    is_leaves_list = [\n",
    "        (False if cl != cr else True)\n",
    "        for cl, cr in zip(children_left_list, children_right_list)\n",
    "    ]\n",
    "\n",
    "    # Store the branches paths\n",
    "    paths = []\n",
    "\n",
    "    for i in range(number_nodes):\n",
    "        if is_leaves_list[i]:\n",
    "            # Search leaf node in previous paths\n",
    "            end_node = [path[-1] for path in paths]\n",
    "\n",
    "            # If it is a leave node yield the path\n",
    "            if i in end_node:\n",
    "                output = paths.pop(np.argwhere(i == np.array(end_node))[0][0])\n",
    "                yield output\n",
    "\n",
    "        else:\n",
    "            # Origin and end nodes\n",
    "            origin, end_l, end_r = i, children_left_list[i], children_right_list[i]\n",
    "\n",
    "            # Iterate over previous paths to add nodes\n",
    "            for index, path in enumerate(paths):\n",
    "                if origin == path[-1]:\n",
    "                    paths[index] = path + [end_l]\n",
    "                    paths.append(path + [end_r])\n",
    "\n",
    "            # Initialize path in first iteration\n",
    "            if i == 0:\n",
    "                paths.append([i, children_left[i]])\n",
    "                paths.append([i, children_right[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_node_info(\n",
    "    label,\n",
    "    node_info,\n",
    "    feature,\n",
    "    threshold,\n",
    "    y_multi,\n",
    "    col_names,\n",
    "    x_multi,\n",
    "    samp_to_leaf,\n",
    "    label_i,\n",
    "):\n",
    "    labels = sorted(y_multi.unique())\n",
    "    leaf_index, branch_idx, branch, impurity, nsamples, ntotal, value = node_info\n",
    "    indent = \"\\t\\t\\t\"\n",
    "    pct_samples = 100.0 * float(nsamples) / float(ntotal)\n",
    "\n",
    "    file_stem = f\"{label}-{label_i}\"\n",
    "    filename = f\"{file_stem}.txt\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\n",
    "            f\"---------------------------------------------------------------------------------------\\n\"\n",
    "        )\n",
    "        f.write(f\"{indent}Branch: {branch_idx}, Path: {branch}\\n\")\n",
    "        f.write(\n",
    "            f\"{indent}{nsamples} in node ({pct_samples}%) (from training + test data)\\n\"\n",
    "        )\n",
    "        f.write(f\"{indent}Gin {impurity} at leaf node {branch[-1]}\\n\")\n",
    "        label_vals = sorted(zip(labels, value), key=lambda tup: tup[1], reverse=True)\n",
    "        weights_str = \" \".join(f\"{l}:{int(v)}\" for l, v in label_vals)\n",
    "        f.write(f\"{indent}Value (from training data): {weights_str}\\n\")\n",
    "        l = []\n",
    "        # Use a feature vector that falls in this leaf_index to determine '<=' or '>'\n",
    "        samp_idxs_in_leaf = samp_to_leaf.index[samp_to_leaf == leaf_index]\n",
    "        samp_idx_in_leaf = samp_idxs_in_leaf[0]\n",
    "        samp_in_leaf = x_multi.iloc[samp_idx_in_leaf]\n",
    "        samp_idxs_df = x_multi.iloc[samp_idxs_in_leaf]\n",
    "        out_df = samp_idxs_df.copy()\n",
    "        out_df.to_csv(f\"{file_stem}.csv\")\n",
    "        for elem in branch:\n",
    "            op = \"<=\" if samp_in_leaf[feature[elem]] <= threshold[elem] else \">\"\n",
    "            lvl = (\n",
    "                \"\"\n",
    "                if col_names[feature[elem]].lower() not in utils.SKILLS\n",
    "                else (f\"(lvl {utils.XPTable.exp_to_level(threshold[elem])})\")\n",
    "            )\n",
    "            s = f\"{col_names[feature[elem]]} {op} {threshold[elem]} {lvl}\"\n",
    "            l.append(s)\n",
    "        f.write(f\"{indent}Decision Rules: \" + \", \".join(l) + \"\\n\")\n",
    "        if pct_samples > 0.5 and label == \"Unknown_bot\":\n",
    "            # Compute some stats for this label's common leaf nodes for convenience.\n",
    "            #   You can do this after the .csv files are output, too.\n",
    "            print(f\"For {filename}: pct_samples > 0.5% and label == 'Unknown_bot'\")\n",
    "            print(f\"Printing df.describe() in {filename}\")\n",
    "            f.write(f\"{indent}{out_df.describe()}\\n\")\n",
    "        f.write(\n",
    "            f\"---------------------------------------------------------------------------------------\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# above ~10 is too deep to graph, so print helpful output instead.\n",
    "TREE_DEPTH = 19\n",
    "print(f\"##############################################################\")\n",
    "print(f\"### Training decision tree with depth {TREE_DEPTH}.#####################\")\n",
    "print(f\"### Generating a label-id.csv file for each leaf node, where #\")\n",
    "print(f\"### label is the tree's classification at that node, and #####\")\n",
    "print(f\"### id is unique for each label. id 0 is the leaf containing #\")\n",
    "print(f\"### the most samples, 1 the next most, etc... ################\")\n",
    "print(f\"### Also generating corresponding label-id.txt files, ########\")\n",
    "print(f\"### containing descriptive info about the .csv file ##########\")\n",
    "print(f\"##############################################################\")\n",
    "clf = classifier.DTclassifier(f\"DTmultiClassifier{TREE_DEPTH}\", max_depth=TREE_DEPTH)\n",
    "score = fit_score(clf, x_multi, y_multi, rpt=True)\n",
    "col_names = x_multi.columns.tolist()\n",
    "\n",
    "n_nodes = clf.tree_.node_count\n",
    "children_left = clf.tree_.children_left\n",
    "children_right = clf.tree_.children_right\n",
    "feature = clf.tree_.feature\n",
    "threshold = clf.tree_.threshold\n",
    "impurity = clf.tree_.impurity\n",
    "value = clf.tree_.value\n",
    "all_branches = list(retrieve_branches(n_nodes, children_left, children_right))\n",
    "label_to_node_info = collections.defaultdict(list)\n",
    "samp_to_leaf = pd.Series(clf.apply(x_multi))\n",
    "leaf_idxs = pd.Series(samp_to_leaf).value_counts()\n",
    "ntotal = leaf_idxs.sum()\n",
    "for index, branch in enumerate(all_branches):\n",
    "    leaf_index = branch[-1]\n",
    "    nsamples = leaf_idxs[leaf_index]\n",
    "    node_info = (\n",
    "        leaf_index,\n",
    "        index,\n",
    "        branch,\n",
    "        impurity[leaf_index],\n",
    "        nsamples,\n",
    "        ntotal,\n",
    "        value[leaf_index][0],\n",
    "    )\n",
    "    label = clf.classes_[np.argmax(value[leaf_index])]\n",
    "    label_to_node_info[label].append(node_info)\n",
    "labels = list(label_to_node_info.keys())\n",
    "for label, v in label_to_node_info.items():\n",
    "    print(\"###################################################\")\n",
    "    print(\"### Generating label files for: \", label, \"########\")\n",
    "    print(\"###################################################\")\n",
    "    for i, node_info in enumerate(sorted(v, key=lambda tup: tup[4], reverse=True)):\n",
    "        print_node_info(\n",
    "            label,\n",
    "            node_info,\n",
    "            feature,\n",
    "            threshold,\n",
    "            y_multi,\n",
    "            col_names,\n",
    "            x_multi,\n",
    "            samp_to_leaf,\n",
    "            i,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tree.export_text(\n",
    "    clf,\n",
    "    feature_names=x_multi.columns.tolist(),\n",
    "    max_depth=100,\n",
    "    show_weights=True,\n",
    "    spacing=1,\n",
    ")\n",
    "with open(\"inspect_dt-tree.txt\", \"w\") as f:\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph some decision trees with lower depths.\n",
    "PLOT_TREES = False\n",
    "if PLOT_TREES:\n",
    "    print(\"Generating small decision tree images (large ones dont display well)\")\n",
    "    scores = []\n",
    "    i_vals = []\n",
    "    for i in range(2, 10):\n",
    "        dt_multi_classifier = classifier.DTclassifier(\n",
    "            f\"DTmultiClassifier{i}\", max_depth=i\n",
    "        )\n",
    "        score = fit_score(dt_multi_classifier, x_multi, y_multi)\n",
    "        scores.append(score)\n",
    "        i_vals.append(i_vals)\n",
    "        out_file = f\"DTmultiClassifer_{i}\"\n",
    "        dot_data = tree.export_graphviz(\n",
    "            dt_multi_classifier,\n",
    "            rotate=True,\n",
    "            impurity=False,\n",
    "            precision=1,\n",
    "            feature_names=x_multi.columns,\n",
    "            class_names=sorted(y_multi.unique()),\n",
    "        )\n",
    "        graph = graphviz.Source(dot_data)\n",
    "        graph.render(filename=out_file, format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_multi.value_counts() / len(y_multi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
