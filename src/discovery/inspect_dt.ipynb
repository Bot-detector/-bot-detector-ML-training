{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path(sys.argv[0]).absolute().parent.parent.parent.parent))\n",
    "base_repo = os.path.realpath(os.path.join(os.getcwd(), \"../../\"))\n",
    "print(f\"{base_repo=}\")\n",
    "\n",
    "sys.path.append(base_repo)\n",
    "\n",
    "# add the entire folder to path\n",
    "print(f\"{sys.path=}\")\n",
    "print(f\"{os.getcwd()=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import utils\n",
    "from src.utils import data\n",
    "from src.utils import classifier\n",
    "\n",
    "import collections\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_FILE = f\"../data/raw/2022-10-26_hiscore_data.parquet.gzip\"\n",
    "\n",
    "df = pd.read_parquet(PATH_TO_FILE)\n",
    "df = df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = os.path.realpath(\"../data/output\")\n",
    "os.chdir(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This logic is roughly equivalent to app.py's train function\n",
    "hiscoredata = data.hiscoreData(df, False)\n",
    "features = hiscoredata.features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_classifier = classifier.classifier(\"binaryClassifier\")\n",
    "dt_binary_classifier = classifier.DTclassifier(\"DTbinaryClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = features.copy()\n",
    "x = x.drop(\n",
    "    columns=[\n",
    "        \"label\",\n",
    "        \"label_id\",\n",
    "        \"name\",\n",
    "        \"created_at\",\n",
    "        \"updated_at\",\n",
    "        \"account_status\",\n",
    "        \"possible_ban\",\n",
    "        \"confirmed_ban\",\n",
    "    ]\n",
    ")\n",
    "print(\"x columns:\\n\", x.columns)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = features[\"label\"].apply(lambda x: 0 if x == \"Real_Player\" else 1)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_score(classifier, x, y, class_names=None, rpt=True):\n",
    "    # This logic is roughly equivalent to app.py's train function\n",
    "    train_x, test_x, train_y, test_y = train_test_split(\n",
    "        x, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    classifier.fit(train_x, train_y)\n",
    "\n",
    "    accuracy, roc_auc = classifier.score(test_y, test_x, class_names)\n",
    "    if rpt:\n",
    "        print(f\"accuracy: {accuracy}, roc_auc: {roc_auc}\")\n",
    "    # OUTPUT: (0.9992126580557206, 0.9992126580557205)\n",
    "\n",
    "    if rpt:\n",
    "        print(classification_report(y_true=test_y, y_pred=classifier.predict(test_x)))\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# To inspect binary classifier random forest and decision tree performance:\n",
    "# fit_score(binary_classifier, x, y)\n",
    "# fit_score(dt_binary_classifier, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of block is x_multi, y_multi. Fiddle around with data here.\n",
    "multi_classifier = classifier.classifier(\"multiClassifier\")\n",
    "dt_multi_classifier = classifier.DTclassifier(\"DTmultiClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = features[\"label\"].value_counts()\n",
    "y_labels = [label for label, value in y_labels.items() if value > 500]\n",
    "y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_multi = features.copy()\n",
    "x_multi = x_multi[x_multi[\"label\"].isin(y_labels)]\n",
    "x_multi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id = dict(\n",
    "    (label, label_id) for label_id, label in enumerate(x_multi[\"label\"].unique())\n",
    ")\n",
    "label_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_multi = x_multi[\"label\"]  # .apply(lambda x: label_to_id[x])\n",
    "y_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum_label = list(enumerate(y_multi.unique()))\n",
    "class_names = [t[1] for t in enum_label]\n",
    "label_to_enum = dict([(k, v) for v, k in enum_label])\n",
    "label_to_enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_multi = x_multi.drop(\n",
    "    columns=[\n",
    "        \"label\",\n",
    "        \"label_id\",\n",
    "        \"name\",\n",
    "        \"created_at\",\n",
    "        \"updated_at\",\n",
    "        \"account_status\",\n",
    "        \"possible_ban\",\n",
    "        \"confirmed_ban\",\n",
    "    ]\n",
    ")\n",
    "x_multi = x_multi[x_multi.columns.drop(list(x_multi.filter(regex=\"/total\")))]\n",
    "x_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_multi columns:\\n\", x_multi.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a decision tree and output info about the set of samples that end up in each leaf node.\n",
    "# Loosely based on: https://stackoverflow.com/a/66299085/5024503\n",
    "def retrieve_branches(number_nodes, children_left_list, children_right_list):\n",
    "    \"\"\"Retrieve decision tree branches\"\"\"\n",
    "\n",
    "    # Calculate if a node is a leaf\n",
    "    is_leaves_list = [\n",
    "        (False if cl != cr else True)\n",
    "        for cl, cr in zip(children_left_list, children_right_list)\n",
    "    ]\n",
    "\n",
    "    # Store the branches paths\n",
    "    paths = []\n",
    "\n",
    "    for i in range(number_nodes):\n",
    "        if is_leaves_list[i]:\n",
    "            # Search leaf node in previous paths\n",
    "            end_node = [path[-1] for path in paths]\n",
    "\n",
    "            # If it is a leave node yield the path\n",
    "            if i in end_node:\n",
    "                output = paths.pop(np.argwhere(i == np.array(end_node))[0][0])\n",
    "                yield output\n",
    "\n",
    "        else:\n",
    "            # Origin and end nodes\n",
    "            origin, end_l, end_r = i, children_left_list[i], children_right_list[i]\n",
    "\n",
    "            # Iterate over previous paths to add nodes\n",
    "            for index, path in enumerate(paths):\n",
    "                if origin == path[-1]:\n",
    "                    paths[index] = path + [end_l]\n",
    "                    paths.append(path + [end_r])\n",
    "\n",
    "            # Initialize path in first iteration\n",
    "            if i == 0:\n",
    "                paths.append([i, children_left[i]])\n",
    "                paths.append([i, children_right[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.utils import XPTable\n",
    "\n",
    "XPTable().df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.utils import XPTable\n",
    "\n",
    "XPTable().exp_to_level(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.utils import XPTable\n",
    "\n",
    "def print_node_info(\n",
    "    label,\n",
    "    node_info,\n",
    "    feature,\n",
    "    threshold,\n",
    "    y_multi,\n",
    "    col_names,\n",
    "    x_multi: pd.DataFrame,\n",
    "    samp_to_leaf,\n",
    "    label_i,\n",
    "    min_samples=100,\n",
    "):\n",
    "    # Get unique labels in the target variable\n",
    "    labels = sorted(y_multi.unique())\n",
    "\n",
    "    # Unpack node information\n",
    "    leaf_index, branch_idx, branch, impurity, n_samples, ntotal, value = node_info\n",
    "\n",
    "    if n_samples < min_samples:\n",
    "        return\n",
    "\n",
    "    # Calculate the percentage of samples in this node\n",
    "    pct_samples = 100.0 * float(n_samples) / float(ntotal)\n",
    "\n",
    "    # Generate the file names\n",
    "    file_stem = f\"{label}-{label_i}\"\n",
    "    filename = f\"{file_stem}.txt\"\n",
    "\n",
    "    # Create a delimiter for separating sections\n",
    "    delimiter_text = \"-\" * 50 + \"\\n\"\n",
    "\n",
    "    # Sort labels based on values for printing purposes\n",
    "    label_vals = sorted(zip(labels, value), key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "    decision_rules = []\n",
    "\n",
    "    # Find the sample indices that fall in this leaf node\n",
    "    samp_idxs_in_leaf = samp_to_leaf.index[samp_to_leaf == leaf_index]\n",
    "    samp_idx_in_leaf = samp_idxs_in_leaf[0]\n",
    "    samp_in_leaf = x_multi.iloc[samp_idx_in_leaf]\n",
    "    samp_idxs_df = x_multi.iloc[samp_idxs_in_leaf]\n",
    "    out_df: pd.DataFrame = samp_idxs_df.copy()\n",
    "\n",
    "    # Export the DataFrame with samples in this leaf node to a CSV file\n",
    "    out_df.to_csv(f\"{file_stem}-#{n_samples}.csv\")\n",
    "\n",
    "    xp_table = XPTable()\n",
    "\n",
    "    # Construct decision rules based on the branch information\n",
    "    for elem in branch:\n",
    "        op = \"<=\" if samp_in_leaf[feature[elem]] <= threshold[elem] else \">\"\n",
    "        column_name = col_names[feature[elem]].lower()\n",
    "\n",
    "        # print(elem, threshold[elem])\n",
    "        if threshold[elem] >0:\n",
    "            level = xp_table.exp_to_level(threshold[elem])\n",
    "        else:\n",
    "            level = 0\n",
    "        \n",
    "        lvl = \"\" if column_name not in utils.SKILLS else (f\"(lvl {level})\")\n",
    "        s = f\"{col_names[feature[elem]]} {op} {threshold[elem]} {lvl}\"\n",
    "        decision_rules.append(s)\n",
    "\n",
    "    # Write information to the output file\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(delimiter_text)\n",
    "        f.write(f\"Branch: {branch_idx}, Path: {branch}\\n\")\n",
    "        f.write(f\"\\t{n_samples} in node ({pct_samples}%) (from training + test data)\\n\")\n",
    "        f.write(f\"\\tGin {impurity} at leaf node {branch[-1]}\\n\")\n",
    "\n",
    "        # Write values associated with each label (if value is not 0)\n",
    "        f.write(f\"\\tValue (from training data):\\n\")\n",
    "        for label, value in label_vals:\n",
    "            if value == 0:\n",
    "                continue\n",
    "            f.write(\"\\t\\t\" + f\"{label}: {value}\" + \"\\n\")\n",
    "\n",
    "        # Write decision rules for the branch\n",
    "        f.write(f\"\\tDecision Rules:\\n\")\n",
    "        for rule in decision_rules:\n",
    "            f.write(f\"\\t\\t\" + str(rule) + \"\\n\")\n",
    "\n",
    "        # Check conditions and write additional statistics for 'Unknown_bot' label\n",
    "        if label == \"Unknown_bot\":\n",
    "            print(f\"For {filename}: label == 'Unknown_bot'\")\n",
    "            print(f\"Printing df.describe() in {filename}\")\n",
    "            f.write(f\"\\t{out_df.describe()}\\n\")\n",
    "        f.write(delimiter_text)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREE_DEPTH = 20\n",
    "\n",
    "print(f\"##############################################################\")\n",
    "print(f\"### Training decision tree with depth {TREE_DEPTH}.#####################\")\n",
    "print(f\"### Generating a label-id.csv file for each leaf node, where #\")\n",
    "print(f\"### label is the tree's classification at that node, and #####\")\n",
    "print(f\"### id is unique for each label. id 0 is the leaf containing #\")\n",
    "print(f\"### the most samples, 1 the next most, etc... ################\")\n",
    "print(f\"### Also generating corresponding label-id.txt files, ########\")\n",
    "print(f\"### containing descriptive info about the .csv file ##########\")\n",
    "print(f\"##############################################################\")\n",
    "\n",
    "clf = classifier.DTclassifier(f\"DTmultiClassifier{TREE_DEPTH}\", max_depth=TREE_DEPTH)\n",
    "score = fit_score(clf, x_multi, y_multi, rpt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# above ~10 is too deep to graph, so print helpful output instead.\n",
    "col_names = x_multi.columns.tolist()\n",
    "\n",
    "n_nodes = clf.tree_.node_count\n",
    "children_left = clf.tree_.children_left\n",
    "children_right = clf.tree_.children_right\n",
    "feature = clf.tree_.feature\n",
    "threshold = clf.tree_.threshold\n",
    "impurity = clf.tree_.impurity\n",
    "value = clf.tree_.value\n",
    "all_branches = list(retrieve_branches(n_nodes, children_left, children_right))\n",
    "samp_to_leaf = pd.Series(clf.apply(x_multi))\n",
    "leaf_idxs = pd.Series(samp_to_leaf).value_counts()\n",
    "ntotal = leaf_idxs.sum()\n",
    "\n",
    "\n",
    "def get_label_node_info(index, branch, leaf_idxs, impurity, ntotal, value, clf_classes):\n",
    "    leaf_index = branch[-1]\n",
    "    n_samples = leaf_idxs[leaf_index]\n",
    "    node_info = (\n",
    "        leaf_index,\n",
    "        index,\n",
    "        branch,\n",
    "        impurity[leaf_index],\n",
    "        n_samples,\n",
    "        ntotal,\n",
    "        value[leaf_index][0],\n",
    "    )\n",
    "    label = clf_classes[np.argmax(value[leaf_index])]\n",
    "    return label, node_info\n",
    "\n",
    "\n",
    "def get_label_to_node_info_dict(all_branches):\n",
    "    label_to_node_info = collections.defaultdict(list)\n",
    "    for index, branch in enumerate(all_branches):\n",
    "        label, node_info = get_label_node_info(\n",
    "            index, branch, leaf_idxs, impurity, ntotal, value, clf.classes_\n",
    "        )\n",
    "        label_to_node_info[label].append(node_info)\n",
    "    return label_to_node_info\n",
    "\n",
    "\n",
    "label_to_node_info = get_label_to_node_info_dict(all_branches)\n",
    "labels = list(label_to_node_info.keys())\n",
    "\n",
    "\n",
    "def generate_label_file(\n",
    "    label, node_info, feature, threshold, y_multi, col_names, x_multi, samp_to_leaf\n",
    "):\n",
    "    print(\"###################################################\")\n",
    "    print(\"### Generating label files for: \", label, \"########\")\n",
    "    print(\"###################################################\")\n",
    "    for i, node_info in enumerate(\n",
    "        sorted(node_info, key=lambda tup: tup[4], reverse=True)\n",
    "    ):\n",
    "        print_node_info(\n",
    "            label,\n",
    "            node_info,\n",
    "            feature,\n",
    "            threshold,\n",
    "            y_multi,\n",
    "            col_names,\n",
    "            x_multi,\n",
    "            samp_to_leaf,\n",
    "            i,\n",
    "        )\n",
    "\n",
    "\n",
    "def generate_label_files(\n",
    "    label_to_node_info, feature, threshold, y_multi, col_names, x_multi, samp_to_leaf\n",
    "):\n",
    "    for label, node_info in label_to_node_info.items():\n",
    "        generate_label_file(\n",
    "            label,\n",
    "            node_info,\n",
    "            feature,\n",
    "            threshold,\n",
    "            y_multi,\n",
    "            col_names,\n",
    "            x_multi,\n",
    "            samp_to_leaf,\n",
    "        )\n",
    "\n",
    "\n",
    "generate_label_files(\n",
    "    label_to_node_info, feature, threshold, y_multi, col_names, x_multi, samp_to_leaf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tree.export_text(\n",
    "    clf,\n",
    "    feature_names=x_multi.columns.tolist(),\n",
    "    max_depth=100,\n",
    "    show_weights=True,\n",
    "    spacing=1,\n",
    ")\n",
    "with open(\"inspect_dt-tree.txt\", \"w\") as f:\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph some decision trees with lower depths.\n",
    "PLOT_TREES = False\n",
    "if PLOT_TREES:\n",
    "    print(\"Generating small decision tree images (large ones dont display well)\")\n",
    "    scores = []\n",
    "    i_vals = []\n",
    "    for i in range(2, 10):\n",
    "        dt_multi_classifier = classifier.DTclassifier(\n",
    "            f\"DTmultiClassifier{i}\", max_depth=i\n",
    "        )\n",
    "        score = fit_score(dt_multi_classifier, x_multi, y_multi)\n",
    "        scores.append(score)\n",
    "        i_vals.append(i_vals)\n",
    "        out_file = f\"DTmultiClassifer_{i}\"\n",
    "        dot_data = tree.export_graphviz(\n",
    "            dt_multi_classifier,\n",
    "            rotate=True,\n",
    "            impurity=False,\n",
    "            precision=1,\n",
    "            feature_names=x_multi.columns,\n",
    "            class_names=sorted(y_multi.unique()),\n",
    "        )\n",
    "        graph = graphviz.Source(dot_data)\n",
    "        graph.render(filename=out_file, format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_multi.value_counts() / len(y_multi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
